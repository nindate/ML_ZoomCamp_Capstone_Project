{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e278d80",
   "metadata": {},
   "source": [
    "## Best Model for Predicting NYC Motor Vehicle Collisions -  \n",
    "\n",
    "Random Forest for Classification is the best model for predicting NYC Collisions. Below is the final code for this model which would be used hereafter for putting as a web service using Flask and local deployment using Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9db0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all the basic libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4904c",
   "metadata": {},
   "source": [
    "Loading the Dataset -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d302e31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH_DATE</th>\n",
       "      <th>CRASH_TIME</th>\n",
       "      <th>PERSON_INJURY</th>\n",
       "      <th>PERSON_AGE</th>\n",
       "      <th>BODILY_INJURY</th>\n",
       "      <th>SAFETY_EQUIPMENT</th>\n",
       "      <th>PERSON_SEX</th>\n",
       "      <th>PERSON_TYPE</th>\n",
       "      <th>PED_LOCATION</th>\n",
       "      <th>CONTRIBUTING_FACTOR_2</th>\n",
       "      <th>...</th>\n",
       "      <th>COMPLAINT</th>\n",
       "      <th>EMOTIONAL_STATUS</th>\n",
       "      <th>VEHICLE_ID</th>\n",
       "      <th>PERSON_ID</th>\n",
       "      <th>CONTRIBUTING_FACTOR_1</th>\n",
       "      <th>POSITION_IN_VEHICLE</th>\n",
       "      <th>PED_ROLE</th>\n",
       "      <th>UNIQUE_ID</th>\n",
       "      <th>PED_ACTION</th>\n",
       "      <th>COLLISION_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-02</td>\n",
       "      <td>21:00</td>\n",
       "      <td>Killed</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Head</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>Pedestrian/Bicyclist/Other Pedestrian at Inter...</td>\n",
       "      <td>Pedestrian/Bicyclist/Other Pedestrian Error/Co...</td>\n",
       "      <td>...</td>\n",
       "      <td>Severe Bleeding</td>\n",
       "      <td>Apparent Death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f2f329b6-2dfc-4bd0-b751-2e4255f1ea06</td>\n",
       "      <td>Traffic Control Disregarded</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>11791937</td>\n",
       "      <td>Crossing Against Signal</td>\n",
       "      <td>4412948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-21</td>\n",
       "      <td>0:00</td>\n",
       "      <td>Killed</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Entire Body</td>\n",
       "      <td>Air Bag Deployed</td>\n",
       "      <td>M</td>\n",
       "      <td>Occupant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Apparent Death</td>\n",
       "      <td>19986231.0</td>\n",
       "      <td>e27e12a2-0485-4e22-b692-3f8a765d2582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Driver</td>\n",
       "      <td>11819198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4419608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>2:00</td>\n",
       "      <td>Killed</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Head</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Occupant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Apparent Death</td>\n",
       "      <td>20091024.0</td>\n",
       "      <td>1a6f5aa7-5125-4be2-8499-fe7977cb0d90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Driver</td>\n",
       "      <td>11998317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4467504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRASH_DATE CRASH_TIME PERSON_INJURY  PERSON_AGE BODILY_INJURY  \\\n",
       "0  2021-05-02      21:00        Killed        62.0          Head   \n",
       "1  2021-05-21       0:00        Killed        24.0   Entire Body   \n",
       "2  2021-10-15       2:00        Killed        30.0          Head   \n",
       "\n",
       "   SAFETY_EQUIPMENT PERSON_SEX PERSON_TYPE  \\\n",
       "0               NaN          F  Pedestrian   \n",
       "1  Air Bag Deployed          M    Occupant   \n",
       "2              None          M    Occupant   \n",
       "\n",
       "                                        PED_LOCATION  \\\n",
       "0  Pedestrian/Bicyclist/Other Pedestrian at Inter...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "                               CONTRIBUTING_FACTOR_2  ...        COMPLAINT  \\\n",
       "0  Pedestrian/Bicyclist/Other Pedestrian Error/Co...  ...  Severe Bleeding   \n",
       "1                                                NaN  ...         Internal   \n",
       "2                                                NaN  ...         Internal   \n",
       "\n",
       "  EMOTIONAL_STATUS  VEHICLE_ID                             PERSON_ID  \\\n",
       "0   Apparent Death         NaN  f2f329b6-2dfc-4bd0-b751-2e4255f1ea06   \n",
       "1   Apparent Death  19986231.0  e27e12a2-0485-4e22-b692-3f8a765d2582   \n",
       "2   Apparent Death  20091024.0  1a6f5aa7-5125-4be2-8499-fe7977cb0d90   \n",
       "\n",
       "         CONTRIBUTING_FACTOR_1 POSITION_IN_VEHICLE    PED_ROLE UNIQUE_ID  \\\n",
       "0  Traffic Control Disregarded                 NaN  Pedestrian  11791937   \n",
       "1                          NaN              Driver      Driver  11819198   \n",
       "2                          NaN              Driver      Driver  11998317   \n",
       "\n",
       "                PED_ACTION COLLISION_ID  \n",
       "0  Crossing Against Signal      4412948  \n",
       "1                      NaN      4419608  \n",
       "2                      NaN      4467504  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the data from source as a csv file and converting it into a Pandas DataFrame:\n",
    "data = pd.read_csv('NYC_Motor_Vehicle_Collisions_to_Person.csv')\n",
    "\n",
    "# Viewing the snapshot of first 5 rows of the loaded dataset:\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f018607",
   "metadata": {},
   "source": [
    "Data Cleaning and Formatting -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67222641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping irrelevant columns from the dataset and assigning remaining dataset to a variable:\n",
    "NYC_df = data.drop(['VEHICLE_ID', 'PERSON_ID','UNIQUE_ID','COLLISION_ID'], axis = 1)\n",
    "\n",
    "# Imputing missing values in PERSON_AGE column with mean PERSON_AGE values:\n",
    "NYC_df['PERSON_AGE'] = NYC_df['PERSON_AGE'].fillna(np.mean(data['PERSON_AGE']))\n",
    "\n",
    "# Imputing missing values in Other columns with 'Unknown' or Most common values:\n",
    "NYC_df['SAFETY_EQUIPMENT'].fillna(\"Unknown\",inplace = True)\n",
    "NYC_df['PED_LOCATION'].fillna(\"Unknown\",inplace = True)\n",
    "NYC_df['CONTRIBUTING_FACTOR_2'].fillna(\"Unspecified\",inplace = True)\n",
    "NYC_df['EJECTION'].fillna(\"Not Ejected\",inplace = True)\n",
    "NYC_df['CONTRIBUTING_FACTOR_1'].fillna(\"Unspecified\",inplace = True)\n",
    "NYC_df['POSITION_IN_VEHICLE'].fillna(\"Unknown\",inplace = True)\n",
    "NYC_df['PED_ACTION'].fillna(\"Unknown\",inplace = True)\n",
    "\n",
    "# converting the 'Crash Date' column to datetime format:\n",
    "NYC_df['CRASH_DATE']= pd.to_datetime(NYC_df['CRASH_DATE'])\n",
    "\n",
    "# converting the 'Person Age' column to integer format:\n",
    "NYC_df['PERSON_AGE']= NYC_df['PERSON_AGE'].astype('int64')\n",
    "\n",
    "# Replacing some values in each column with specific values:\n",
    "# Changing \"Does Not Apply\" to \"Unknown\"or \"None\" \n",
    "NYC_df['BODILY_INJURY'].replace('Does Not Apply','None',inplace=True)  \n",
    "NYC_df['PERSON_SEX'].replace('U','M',inplace=True)\n",
    "NYC_df['PED_LOCATION'].replace('Does Not Apply','Unknown',inplace=True)\n",
    "NYC_df['COMPLAINT'].replace('Does Not Apply','Unknown',inplace=True)\n",
    "NYC_df['EMOTIONAL_STATUS'].replace('Does Not Apply','Unknown',inplace=True)\n",
    "NYC_df['PED_ACTION'].replace('Does Not Apply','Unknown',inplace=True)\n",
    "NYC_df['PERSON_INJURY'].replace({'Injured': 0 ,'Killed': 1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb8f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting Months to abbreviated Month Names:\n",
    "month_name = []\n",
    "\n",
    "# Extracting Months from Crash_Date and using it to get abbreviated month names using for loop:\n",
    "crash_month = pd.DatetimeIndex(NYC_df['CRASH_DATE']).month\n",
    "for i in crash_month:\n",
    "    mnth_abb = calendar.month_abbr[i]\n",
    "    month_name.append(mnth_abb)\n",
    "\n",
    "# assigning month name to a column\n",
    "NYC_df['CRASH_Mnth_Name'] = month_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdb7dc",
   "metadata": {},
   "source": [
    "Splitting the Data and getting the Feature Matrix & Target variables -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee268a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27401, 17), (9134, 17), (9134, 17))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the dataset using sklearn into 60-20-20:\n",
    "# Step 1 - splitting dataset into full train and test subsets first:\n",
    "df_full_train, df_test = train_test_split(NYC_df, test_size=0.2,random_state=1) \n",
    "\n",
    "# Step 2 - splitting full train subset again into training set and validation set:\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25,random_state = 1)\n",
    "\n",
    "# Resetting indices for each of the subset: \n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Getting our target variable column ('PERSON_INJURY') subsets as respective Numpy arrays:\n",
    "y_train = df_train.PERSON_INJURY\n",
    "y_val = df_val.PERSON_INJURY\n",
    "y_test = df_test.PERSON_INJURY\n",
    "\n",
    "# Deleting 'PERSON_INJURY' or target column from feature matrix subsets:\n",
    "del df_train['PERSON_INJURY']\n",
    "del df_val['PERSON_INJURY']\n",
    "del df_test['PERSON_INJURY']\n",
    "\n",
    "# Re-checking the size of 3 subsets after deleting the target column:\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89461125",
   "metadata": {},
   "source": [
    "Predicting on Test data using our Final Model (Random Forest for Classification) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f009aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "# resetting indices of full_train DataFrame:\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "\n",
    "# Encode string class values of target variable PERSON_INJURY column as integers - using LabelEncoder():\n",
    "#label_encoder = LabelEncoder()\n",
    "y_full_train = label_encoder.fit_transform(df_full_train.PERSON_INJURY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab90c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the CRASH_DATE column as a Timestamp and converting it into an integer data type for \n",
    "# df_full_train and df_test subsets:\n",
    "df_full_train['CRASH_DATE'] = df_full_train['CRASH_DATE'].map(pd.Timestamp.timestamp).astype(int)\n",
    "df_test['CRASH_DATE'] = df_test['CRASH_DATE'].map(pd.Timestamp.timestamp).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890e432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning the full train df into dictionaries:\n",
    "dicts_full_train = df_full_train.to_dict(orient='records')\n",
    "\n",
    "# instantiating the vectorizer instance:\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# turning list of dictionaries into full train feature matrix\n",
    "X_full_train = dv.fit_transform(dicts_full_train)\n",
    "\n",
    "# turning the test df into dictionaries:\n",
    "dicts_test = df_test.to_dict(orient='records')\n",
    "\n",
    "# turning list of dictionaries into testing feature matrix\n",
    "X_test = dv.transform(dicts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0f2a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test Rand_Forest: 0.998\n"
     ]
    }
   ],
   "source": [
    "# Using the Final Random Forest Classifier -\n",
    "rf = RandomForestClassifier(random_state=42, max_depth=15, min_samples_leaf = 1, max_features = 8, n_estimators = 70)\n",
    "\n",
    "# training our train set with above optimal parameters:\n",
    "model = rf.fit(X_full_train, y_full_train)\n",
    "\n",
    "# predicting the Random Forest for Classification model on the testing set:\n",
    "y_pred2 = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# computing the AUC score on testing set:\n",
    "print('AUC on test Rand_Forest: %.3f' % roc_auc_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce56e4e",
   "metadata": {},
   "source": [
    "#### Using KFold Cross-Validation on our Final Model for making Predictions - \n",
    "\n",
    "(making 5-fold cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3044ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 -\n",
    "# Function 1 - Creating a function to train our DataFrame:\n",
    "def train(df_train, y_train):\n",
    "    dicts = df_train.to_dict(orient='records')\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "    \n",
    "    model = rf.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67717ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - \n",
    "# Function 2 - Creating another function to predict:\n",
    "def predict(df, dv, model):\n",
    "    dicts = df.to_dict(orient='records')  # converts df to list of dictionaries\n",
    "    \n",
    "    X = dv.transform(dicts)  # creates a feature matrix using the vectorizer\n",
    "    y_pred = model.predict(X) # uses the model\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e5963b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the number of folds to be used:\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86c30c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933 +- 0.018\n"
     ]
    }
   ],
   "source": [
    "# Performing K-fold Cross validation and evaluating the AUC scores after each iteration:\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    \n",
    "    # Selecting part of dataset as 3 subsets for model:\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "    \n",
    "    y_train = df_train.PERSON_INJURY.values\n",
    "    y_val = df_val.PERSON_INJURY.values\n",
    "    \n",
    "    dv, model = train(df_train, y_train)   # using train function created\n",
    "    y_pred = predict(df_val, dv, model)   # using predict function created\n",
    "    \n",
    "    # compute auc scores for each iteration or fold in KFold:\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "    \n",
    "# Computing mean of AUC scores and spread of AUC score:\n",
    "print('%.3f +- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "056c721a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9418604651162791, 0.9605263157894737, 0.9125, 0.9125, 0.9387755102040816]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the listing of AUC scores in each fold:\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9106241a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5232558139534884"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, Training our Final Model on Full train dataset and evaluating on test dataset -\n",
    "dv, model = train(df_full_train, y_full_train)  \n",
    "y_pred = predict(df_test, dv, model)   # using predict function created\n",
    "\n",
    "# compute auc for ROC Curve:\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f33a846",
   "metadata": {},
   "source": [
    "#### Saving the Model -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b347b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3cd4861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.bin'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - taking our model and writing it to a file - \n",
    "# creating a file where we'll write it:\n",
    "output_file = f'model.bin'                  \n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ab8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a Binary file using pickle - alternative to open and close codes we use with open to automatically open-close a file:\n",
    "with open(output_file, 'wb') as f_out:    # file output\n",
    "    pickle.dump((dv, model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd9208b",
   "metadata": {},
   "source": [
    "#### Loading the Model -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12fe7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4fefcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a variable with our model file:\n",
    "input_file = 'model.bin'\n",
    "\n",
    "# loads our model file: \n",
    "with open(input_file, 'rb') as f_in:    # file input; rb - used to read the file\n",
    "    dv, model = pickle.load(f_in)     # load() function reads from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "003d9bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, max_features=8, n_estimators=70,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31b61797",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_collided_person = {'CRASH_DATE': 1618704000,\n",
    "                          'CRASH_TIME' : 12,\n",
    "                          'PERSON_AGE' : 45,\n",
    "                          'BODILY_INJURY' : 'Head', \n",
    "                          'SAFETY_EQUIPMENT' : 'Lap Belt & Harness',\n",
    "                          'PERSON_SEX' : 'M', \n",
    "                          'PERSON_TYPE' : 'Pedestrian',\n",
    "                          'PED_LOCATION': 'Unknown', \n",
    "                          'CONTRIBUTING_FACTOR_2' : 'Pedestrian/Bicyclist/Other Pedestrian Error/Confusion', \n",
    "                          'EJECTION' : 'Not Ejected',\n",
    "                          'COMPLAINT' : 'Internal',\n",
    "                          'EMOTIONAL_STATUS' : 'Apparent Death', \n",
    "                          'CONTRIBUTING_FACTOR_1' : 'Unspecified', \n",
    "                          'POSITION_IN_VEHICLE' : 'Unknown',\n",
    "                          'PED_ROLE' : 'Pedestrian', \n",
    "                          'PED_ACTION' : 'Crossing With Signal', \n",
    "                          'CRASH_Mnth_Name' : 'Jun'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5f8f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the sample_collided_person's feature details into a dictionary using DictVectorizer:\n",
    "X = dv.transform([sample_collided_person])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93de430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on sample person using our model: \n",
    "y_pred = model.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13d02cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: {'CRASH_DATE': 1618704000, 'CRASH_TIME': 12, 'PERSON_AGE': 45, 'BODILY_INJURY': 'Head', 'SAFETY_EQUIPMENT': 'Lap Belt & Harness', 'PERSON_SEX': 'M', 'PERSON_TYPE': 'Pedestrian', 'PED_LOCATION': 'Unknown', 'CONTRIBUTING_FACTOR_2': 'Pedestrian/Bicyclist/Other Pedestrian Error/Confusion', 'EJECTION': 'Not Ejected', 'COMPLAINT': 'Internal', 'EMOTIONAL_STATUS': 'Apparent Death', 'CONTRIBUTING_FACTOR_1': 'Unspecified', 'POSITION_IN_VEHICLE': 'Unknown', 'PED_ROLE': 'Pedestrian', 'PED_ACTION': 'Crossing With Signal', 'CRASH_Mnth_Name': 'Jun'}\n",
      "output: 0.3589322914227006\n"
     ]
    }
   ],
   "source": [
    "print('input:', sample_collided_person)\n",
    "print('output:', float(y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "037d3d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying the collision_injury decision for our model by specifying the threshold >= 0.55:\n",
    "collision_injury = float(y_pred) >= 0.55 \n",
    "collision_injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1b983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
